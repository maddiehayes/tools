######################################
# Lenses 2.3 Sample Configuration File
######################################

# Settings that are commented out will use the default value. They are not
# required to be set explicitly.

###

## The mandatory options for Lenses to start with a PLAINTEXT connection to
## the brokers, are:
## - lenses.license.file
## - lenses.secret.file
## - lenses.kafka.brokers

## The options that may be important to provide a good Lenses experience, are:
## - lenses.zookeeper.hosts
## - lenses.schema.registry.urls
## - lenses.kafka.connect.clusters
## - lenses.storage.directory
## - lenses.sql.state.dir

###

#############################
# Listener and Basic Settings
#############################

## Set the ip:port for Lenses to bind to and optionally a JMX port

lenses.ip = 0.0.0.0
lenses.port = 9991
lenses.jmx.port = 9102

## License file allowing connecting to up to N brokers

lenses.license.file = "/data/license.json"

## Security configuration is managed in an external file

lenses.secret.file = "/data/security.conf"

## Path to a directory Lenses can store data in. Currently Data Policies are
## stored here. This directory and its contents should be kept between upgrades.

lenses.storage.directory = "/data/storage_dir"


#####################################
# Kafka Cluster and External Services
#####################################

# Kafka Brokers

## The bootstrap servers Lenses should use, a list of a few brokers, just as you
## would set for any Kafka client app. The default value is empty and it's
## mandatory to set it.

lenses.kafka.brokers = "PLAINTEXT://kafkadev-kafka1.cidev.sas.us:9092,PLAINTEXT://kafkadev-kafka2.cidev.sas.us:9092,PLAINTEXT://kafkadev-kafka3.cidev.sas.us:9092,PLAINTEXT://kafkadev-kafka4.cidev.sas.us:9092,PLAINTEXT://kafkadev-kafka5.cidev.sas.us:9092"
## Lenses detect brokers JMX ports via zookeeper. If you don't setup Lenses with
## Zookeeper, then you have to explicitly set your brokers JMX ports. If all
## brokers use the same port for JMX, set the simpler
## `lenses.kafka.metrics.default.port` option. If each broker listens for JMX
## connections on a different port, use the more complex
## `lenses.kafka.metrics`.

## Simple setup, all brokers use the same, unprotected JMX port:
lenses.kafka.metrics.default.port = 9393

# Zookeeper

## The complete list of your zookeeper nodes. It is optional for Lenses to work
## but required if you want to configure *quotas* via Lenses. Zookeeper JMX is
## optional when zookeeper is set. For advanced metrics setup, please check the
## documentation.

lenses.zookeeper.hosts = [
  {url:"kafkadev-zookeeper1.cidev.sas.us:2181", metrics:{url:"kafkadev-zookeeper1.cidev.sas.us:9394", type:"JMX"}},
  {url:"kafkadev-zookeeper2.cidev.sas.us:2181", metrics:{url:"kafkadev-zookeeper2.cidev.sas.us:9394", type:"JMX"}},
  {url:"kafkadev-zookeeper3.cidev.sas.us:2181", metrics:{url:"kafkadev-zookeeper3.cidev.sas.us:9394", type:"JMX"}}
]

## If zookeeper support above is enabled and Kafka is set under a Kafka chroot,
## please set the address here.

lenses.zookeeper.chroot = "/kafka"


# Schema Registry

## The complete list of your schema registry nodes. Schema Registry is required
## if Lenses must decode and work with AVRO messages. If the list is not
## complete, Lenses will still work but won't be able to monitor the health of
## the missing nodes. JMX is optional. For advanced metrics setup, please check
## the documentation.

lenses.schema.registry.urls = [
  {url: "http://kafkadev-connect1.cidev.sas.us:8081", metrics:{url:"kafkadev-connect1.cidev.sas.us:9391", type:"JMX"}},
  {url: "http://kafkadev-connect2.cidev.sas.us:8081", metrics:{url:"kafkadev-connect2.cidev.sas.us:9391", type:"JMX"}},
  {url: "http://kafkadev-connect3.cidev.sas.us:8081", metrics:{url:"kafkadev-connect3.cidev.sas.us:9391", type:"JMX"}}
]

## The topic where Schema Registry stores its schemas (if it's not the default
## `_schemas`) and whether to allow deleting schemas.

lenses.schema.registry.topics = "_schemas"
lenses.schema.registry.delete = true

# Kafka Connect

## The complete list of your Kafka Connect worker nodes (if you use connect),
## grouped by cluster. You also need to set their configuration topics. JMX is
## optional. If you omit some workers from each cluster, Lenses will still work
## but will be unable to monitor the health of the missing nodes, or get
## monitoring data from them. If your Connect workers use Basic Authentication
## then you need to set the authentication information as well.
## For advanced metrics setup, please check out the documentation.

lenses.kafka.connect.clusters = [
  {
    name: "dev",
    urls: [
      {url:"http://kafkadev-connect1.cidev.sas.us:8083", metrics:{url:"kafkadev-connect1.cidev.sas.us:9392", type:"JMX"}},
      {url:"http://kafkadev-connect2.cidev.sas.us:8083", metrics:{url:"kafkadev-connect2.cidev.sas.us:9392", type:"JMX"}},
      {url:"http://kafkadev-connect3.cidev.sas.us:8083", metrics:{url:"kafkadev-connect3.cidev.sas.us:9392", type:"JMX"}}
    ],
    statuses: "connect-status",
    configs: "connect-configs",
    offsets: "connect-offsets"
  }
]

# AlertManager

## The alertmanager endpoints (if you use am). Whilst an exhaustive list is not
## needed, it's wise to set at least a couple, so if one alertmanager node is
## down, another can be used.

#lenses.alert.manager.endpoints = "" # "http://am-host-1:port,http://am-host-2:port"

## It's a good idea to set these, so you can identify your alerts and route them easily.

#lenses.alert.manager.source = "Lenses"
#lenses.alert.manager.generator.url = ""  # A unique URL identifying the creator of this alert.


# Grafana

## If you've setup the Lenses Monitoring Suite, you can set the Grafana address here
## so you get a link to it from inside Lenses UI.

lenses.grafana = "http://kafkadev-utilities.cidev.sas.us:3000"


#############################
# Lenses Streaming SQL Engine
#############################

## Lenses SQL Execution Modes set where your LSQL queries will run.
## In the default setting `IN_PROC`, queries run inside Lenses. Whilst a great way
## to try LSQL, it doesn't scale as well, with the bottleneck being network and/or CPU
## of the single server that runs Lenses. `CONNECT` mode will run the queries in your
## Kafka Connect cluster(s) provided you added the LSQL connector. `KUBERNETES` will
## run the queries in your kubernetes cluster, once set up with the keys to Landoop's
## container registry.

lenses.sql.execution.mode = "IN_PROC" # "IN_PROC" | "CONNECT" | "KUBERNETES"

## Lenses SQL processing engine needs a temporary directory to store
## scratch files. It's important that Lenses (when you run `IN_PROC`)
## or Connect (when you run in `CONNECT`) can write to the path below.
## It can be absolute or relative.

lenses.sql.state.dir = "/install/citng/lenses-sql-kstream-state"

## When in `KUBERNETES` mode, the kube config file and the service account to
## use, should be set.

# lenses.kubernetes.config.file = "/home/lenses/.kube/config"
# lenses.kubernetes.service.account = "default"


###################
# Advanced Settings
###################

###

## It's advised to change the settings below only after you succesfully deployed
## Lenses. Depending on your cluster size and usage, a few tweaks may be needed.
## Feel free to join our community at https://launchpass.com/landoop-community
## or contact support if you need help.

###

# Lenses State Topics

## These topics are used to store state. They are created on startup if they do
## not exist.

#lenses.topics.audits = "_kafka_lenses_audits"
#lenses.topics.metrics = "_kafka_lenses_metrics"
#lenses.topics.cluster = "_kafka_lenses_cluster"
#lenses.topics.profiles = "_kafka_lenses_profiles"
#lenses.topics.processors = "_kafka_lenses_processors"
#lenses.topics.connectors = "_kafka_lenses_connectors"
#lenses.topics.alerts.storage = "_kafka_lenses_alerts"
#lenses.topics.lsql.storage = "_kafka_lenses_lsql_storage"
#lenses.topics.alerts.settings = "_kafka_lenses_alerts_settings"
#lenses.topics.metadata = "_kafka_lenses_topics_metadata"
#lenses.topics.external.topology = "__topology"
#lenses.topics.external.metrics = "__topology__metrics"


# Lenses SQL

## Set up Lenses SQL

#lenses.sql.max.bytes = 20971520
#lenses.sql.max.time = 3600000
#lenses.sql.sample.default = 2 # Sample 2 messages every 200 msec
#lenses.sql.sample.window = 200

#lenses.sql.monitor.frequency = 10000

## When in `KUBERNETES` mode you can tweak the LSQL kubernetes images and pods.

# Kubernetes configuration. Enable your enterprise subscriptions @ info@landoop.com
# lenses.kubernetes.processor.image.name = "eu.gcr.io/lenses-container-registry/lenses-sql-processor"
# lenses.kubernetes.processor.image.tag = "2.3"
# lenses.kubernetes.pull.policy = "IfNotPresent"
# lenses.kubernetes.watch.reconnect.limit = 10
# lenses.kubernetes.runner.mem.limit = "768Mi"
# lenses.kubernetes.runner.mem.request = "512Mi"
# lenses.kubernetes.runner.java.opts = "-Xms256m -Xmx512m -XX:MaxPermSize=128m -XX:MaxNewSize=128m -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+DisableExplicitGC -Djava.awt.headless=true"

# Lenses

## Set up Lenses workers

#lenses.metrics.workers = 16
#lenses.offset.workers = 5

## Lenses internal refresh (in msec)

#lenses.interval.summary = 10000
#lenses.interval.consumers = 10000
#lenses.interval.partitions.messages = 10000
#lenses.interval.type.detection = 30000
#lenses.interval.user.session.ms = 14400000
#lenses.interval.user.session.refresh = 60000
#lenses.interval.schema.registry.healthcheck = 30000
#lenses.interval.topology.topics.metrics = 10000
#lenses.interval.processor.metrics.buffer.ms = 10000
#lenses.interval.alert.manager.healthcheck = 5000
#lenses.interval.alert.manager.publish = 30000

#lenses.interval.jmx.refresh.zk = 30000
#lenses.interval.jmx.refresh.sr = 30000
#lenses.interval.jmx.refresh.broker = 30000
#lenses.interval.jmx.refresh.alert.manager = 30000
#lenses.interval.jmx.refresh.connect = 30000
#lenses.interval.jmx.refresh.brokers.in.zk = 10000

## Lenses Web Socket API

#lenses.kafka.ws.poll.ms = 1000
#lenses.kafka.ws.buffer.size = 10000
#lenses.kafka.ws.max.poll.records = 1000
#lenses.kafka.ws.heartbeat.ms = 30000

## CORS

#lenses.access.control.allow.methods = "GET,POST,PUT,DELETE,OPTIONS"
#lenses.access.control.allow.origin = "*"

## Whether to allow self-signed certificates and telemetry

#lenses.allow.weak.SSL = true
#lenses.telemetry.enable = true

## Zookeeper connections configs

#lenses.curator.retries = 3
#lenses.curator.initial.sleep.time.ms = 2000
#lenses.zookeeper.max.session.ms = 10000
#lenses.zookeeper.max.connection.ms = 10000

## Tweak Akka

#lenses.akka.request.timeout.ms = 10000

## List of topics Lenses should treat as `system topics`

#lenses.kafka.control.topics = [
#     "connect-configs",
#     "connect-offsets",
#     "connect-status",
#     "connect-statuses",
#     "_schemas",
#     "__consumer_offsets",
#     "_kafka_lenses_",
#     "lsql_",
#     "__transaction_state"
#   ]

## Alerts bugger
#lenses.alert.buffer.size = 100


# Kafka

## You can set any option for the producers, consumers and kstreams clients of
## Lenses by prefixing the setting accordingly.

# lenses.kafka.settings.consumer.XXX
# lenses.kafka.settings.producer.XXX
# lenses.kafka.settings.kstream.XXX

## we override the aggressive defaults. Don't go too low as it will affect
## performance when the cluster is down

# lenses.kafka.settings.consumer = {
#   reconnect.backoff.ms = 1000
#   retry.backoff.ms = 1000
# }
# lenses.kafka.settings.producer {
#   reconnect.backoff.ms = 1000
#   retry.backoff.ms = 1000
# }

## Default compression settings used by Lenses Kafka clients. Mainly affects the
## Lenses state topics.

lenses.kafka.settings.consumer.compression.type = snappy
lenses.kafka.settings.producer.compression.type = snappy
